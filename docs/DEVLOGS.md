# NeuroTIC Dev Log ğŸ§ 

The journey from a single XOR problem to a fully hackable neural network toolkit.

1. AI can't be an infinite number of nested ifs. How does it really work?
2. Boolean perceptron looks easy to be coded.
3. Everything is just weights, biases, and error calculations... to automate the adjustments.
4. âŒ Why canâ€™t XOR be solved!?
5. ğŸ§® Oh, I need more neurons.
6. ğŸ‹ï¸ How to train a full network?
7. ğŸ› ï¸ I need tools to build and train networks.
8. ğŸš€ This is starting to feel like a real system! Let's go deeper.
9. ğŸ§± First, neurons must be treated as objects â€” letâ€™s encapsulate their properties in a structure.
10. ğŸ”Œ What if their connections emulate electrical wiring, using inputs as pointers and outputs as variables?
11. ğŸ—‚ï¸ If I want to create flexible functions to control the network... I need structure. Time to build a network struct with a dynamic neuron matrix, topology info, and external connections.
12. ğŸ•¸ï¸ With pointers and dynamic memory â€” any topology is possible!
13. ğŸ§¼ Right... but I have to respect memory space. Time to add buffers between layers.
